= Capacity planning for connections
:last_updated: 08/10/2021
:linkattrs:
:page-partial:
:page-aliases:
:experimental:
:description: Using Connections, you can perform live queries on external databases.

This article provides hardware requirements and recommendations for using connections with ThoughtSpot. Please note that actual hardware requirements will vary depending on many factors like number of users, groups, worksheets, Liveboards, and more.

These recommendations are only for connections to cloud data warehouses in ThoughtSpot.

== ThoughtSpot Architecture

=== Single node
image::cap_planning_illo_1.png[]

=== Multi-node
image::cap_planning_illo_2.png[]

== Factors influencing capacity

There are numerous factors which affect the capacity required for connections in ThoughtSpot.

=== Number of concurrent active users

The number of concurrent active users is the number of users actively interacting with ThoughtSpot at any point in time. More concurrent active users mean more requests to the system which require CPU and memory to process these requests.

The number of requests that the system can handle depends on the type of request and metadata in the system. For example, CPU and memory required to make object metadata create/update calls are higher than object read calls. Similarly a customer with a large number of users/groups may need more resources to process the same request compared to a customer with a simpler setup.

It is also important to note that the cloud data warehouse can also limit the total number of requests that a system can handle. Tuning and scaling the cloud data warehouse to meet request-rate requirements is beyond the scope of this documentation.

The general recommendation is that ThoughtSpot can handle 30 concurrent read request/sec with 16 vCPU/128 GB RAM provided the cloud data warehouse is able to handle the query load.

It is important to understand the usage pattern of the users to figure out the request rate generated by concurrent active users.

For example, if an active user opens a Liveboard which issues 20 requests and then takes 4 minutes to go through the visualizations in the Liveboard, they are generating 5 requests/min. This means at 30 requests/sec, 16 vCPU/128 GB RAM system can handle 360 concurrent active users. Please refer to xref:scale-up-out[Scale Up/Out]  for more information on how to set up the cluster for a higher request rate.  There is no single rule that can help with this calculation so it is recommended that every customer do their own testing to find out the peak load and setup capacity accordingly.

=== Total number of objects in the system

ThoughtSpot server caches all the objects and metadata associated with objects in memory so that it can serve user requests with low latency. These cached objects are replicated across all the nodes. During processing of user requests, services might make copies of objects as well. This requires the system to have sufficient memory to store and process objects. Actual amount of memory required depends on the type and complexity of objects in the system. Some of the examples of objects that takes up memory are:

- Worksheets with large number of columns
- Liveboards with many visualizations
- User groups with a large number of users
- Overall number of connections, worksheets,Liveboards, users, groups, and views

In general, ThoughtSpot can hold and serve up to 500K objects in 128GB of RAM.

=== Number of indexed tokens

- xref:data-modeling-index.adoc[Manage suggestion indexing] provides details of what indexing is and how to control what is indexed or not. Based on the data model and data, customer should be able to get an estimate of number of tokens that will be indexed.
- In general we have seen 500MB of memory/1M token. It is a general recommendation and actual memory usage will depend on the size of each token.
- Data tokens are replicated on 2 nodes in a multi-node cluster so total memory required to hold indexed data tokens is twice the memory required for holding total number of tokens in a multi-node cluster.

== Disk capacity

Disk capacity required depends on the following factors:

- Number of snapshots
- Total number of Indexed tokens
- Total number of objects in the system

== Minimum hardware requirements for production

These are the minimum hardware requirements for a single-node cluster to run a ThoughtSpot application. For a multi-node setup, you can replicate this

|===
|vCPU |RAM |Premium SSD Managed Disk Volume |Boot Volume

|16 vCPU
|128 GB RAM
|2 * 400GB
|250 GB
|===

[#scale-up-out]
== Scale up/out capability

ThoughtSpot is designed to scale up or scale out linearly with request rate. This means that a 2-node cluster can handle twice the number of requests compared to a single-node cluster. Similarly, a single node with 2X CPU and 2Y RAM can also handle twice the number of requests compared to a node with X CPU and Y RAM.

ThoughtSpot replicates all the Metadata and Objects across all nodes in the cluster so it does not scale out with increase in Metadata size. The only way to fit more metadata in the cluster will be to scale it up by adding more memory to the system.

== High Availability

ThoughtSpot is designed to be Highly Available. Highly available setup ensures that ThoughtSpot application is available to the user in case one node fails. For High Availability setup, at least 3 nodes are required in the cluster.

You can also choose a backup or snapshot strategy to recover from failure. You can learn more about how to set up the backup and snapshot configuration for your cluster in xref:backup-strategy.adoc[Choose a backup strategy].
